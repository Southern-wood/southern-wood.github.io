<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>如何在共享的 Linux 服务器上合理使用资源 | Southern</title>
<meta name=keywords content="linux"><meta name=description content="我目前在外校的网络安全实验室线上实习，实验室有一台共享的 Linux 服务器，我至今为止的所有工作几乎都是在这台服务器上完成的。
尽管有一定的 Linux 使用经验，但是我还是在整个实习过程中遇到了比较多的问题。究其原因，使用一台属于自己的 Linux 本地机器，和作为一个普通用户访问共享的 Linux 服务器，这之间还是有较大的区别的。"><meta name=author content="wood"><link rel=canonical href=https://Southern-wood.github.io/post/2025/1/how-to-use-resources-on-a-shared-linux-server/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.dbd2bc681cd728315dd5183f09339f07a6e37a6d6f019181d7577f70f1fae335.css integrity="sha256-29K8aBzXKDFd1Rg/CTOfB6bjem1vAZGB11d/cPH64zU=" rel="preload stylesheet" as=style><link rel=icon href=https://Southern-wood.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://Southern-wood.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Southern-wood.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://Southern-wood.github.io/apple-touch-icon.png><link rel=mask-icon href=https://Southern-wood.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://Southern-wood.github.io/post/2025/1/how-to-use-resources-on-a-shared-linux-server/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css integrity=sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js integrity=sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://Southern-wood.github.io/post/2025/1/how-to-use-resources-on-a-shared-linux-server/"><meta property="og:site_name" content="Southern"><meta property="og:title" content="如何在共享的 Linux 服务器上合理使用资源"><meta property="og:description" content="我目前在外校的网络安全实验室线上实习，实验室有一台共享的 Linux 服务器，我至今为止的所有工作几乎都是在这台服务器上完成的。
尽管有一定的 Linux 使用经验，但是我还是在整个实习过程中遇到了比较多的问题。究其原因，使用一台属于自己的 Linux 本地机器，和作为一个普通用户访问共享的 Linux 服务器，这之间还是有较大的区别的。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-01-23T00:00:00+08:00"><meta property="article:modified_time" content="2025-01-23T00:00:00+08:00"><meta property="article:tag" content="Linux"><meta property="og:image" content="https://Southern-wood.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Southern-wood.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="如何在共享的 Linux 服务器上合理使用资源"><meta name=twitter:description content="我目前在外校的网络安全实验室线上实习，实验室有一台共享的 Linux 服务器，我至今为止的所有工作几乎都是在这台服务器上完成的。
尽管有一定的 Linux 使用经验，但是我还是在整个实习过程中遇到了比较多的问题。究其原因，使用一台属于自己的 Linux 本地机器，和作为一个普通用户访问共享的 Linux 服务器，这之间还是有较大的区别的。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://Southern-wood.github.io/post/"},{"@type":"ListItem","position":2,"name":"如何在共享的 Linux 服务器上合理使用资源","item":"https://Southern-wood.github.io/post/2025/1/how-to-use-resources-on-a-shared-linux-server/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"如何在共享的 Linux 服务器上合理使用资源","name":"如何在共享的 Linux 服务器上合理使用资源","description":"我目前在外校的网络安全实验室线上实习，实验室有一台共享的 Linux 服务器，我至今为止的所有工作几乎都是在这台服务器上完成的。\n尽管有一定的 Linux 使用经验，但是我还是在整个实习过程中遇到了比较多的问题。究其原因，使用一台属于自己的 Linux 本地机器，和作为一个普通用户访问共享的 Linux 服务器，这之间还是有较大的区别的。\n","keywords":["linux"],"articleBody":"我目前在外校的网络安全实验室线上实习，实验室有一台共享的 Linux 服务器，我至今为止的所有工作几乎都是在这台服务器上完成的。\n尽管有一定的 Linux 使用经验，但是我还是在整个实习过程中遇到了比较多的问题。究其原因，使用一台属于自己的 Linux 本地机器，和作为一个普通用户访问共享的 Linux 服务器，这之间还是有较大的区别的。\n这篇文章里，我想分享下我使用服务器中用到的一些工具，遇到的问题以及解决方案。\nSSH 连接工具 我找不出任何不推荐 VS Code Remote-SSH 插件的理由。\n只需要简单的配置，你就可以使用本地的 VS Code 终端编辑远程服务器上的文件，同时，所有的插件和配置都能方便地同步到远程服务器上，体验上和本地写代码并没有区别。\n最重要的是，Github Copilot 也能在远程服务器上方便地访问。使用过 AI Copilot 后，我很难回到没有 AI 插件的环境了，由俭入奢易，由奢入俭难啊。\n并行化工具 在服务器上，我经常需要同时运行多个任务。特别常见的场景是，同一段代码需要在不同的数据集或者不同的参数设置下进行评估。\n这种情况如果在本地的机器，我可能会用 GNU Parallel；但是服务器上并没有安装这个工具。作为一个替代方案，我常用的方式是手动写一个 shell 脚本来管理任务。\n例如，main.py 这个程序需要在 10 个数据集上运行，我写的 shell 脚本可能会像这样：\n#!/bin/bash for i in {1..10} do nohup python main.py --dataset dataset_$i 2\u003e\u00261 \u003e output_$i.log \u0026 done 这里的 nohup 是用来创建后台进程，如果不使用 nohup 直接运行 python main.py，在 SSH 连接中断后程序会停止运行；\u0026 是用来将任务放到后台运行，和当前的终端分离。\n当然，这是只是最粗糙的并行脚本，它的问题有很多，最容易想到的有两点：\n一些任务可能会占用太多的 CPU/GPU 资源，导致服务器上的其他任务无法正常运行。 所有任务的输出都被 nohup 默认重定向到 nohup.out 文件，这样会导致输出混乱，不方便查看。 所以，我实际上会在脚本里手动控制并行任务的数量，并将输出重定向到不同的文件中。\n#!/bin/bash max_jobs=5 current_jobs=0 for i in {1..10} do if [ $current_jobs -ge $max_jobs ]; then wait -n current_jobs=$((current_jobs-1)) fi nohup python main.py --dataset $i 2\u003e\u00261 \u003e output_$i.log \u0026 current_jobs=$((current_jobs+1)) done CPU 资源控制 虽然上面展示的仍然是一个比较粗糙和简单的脚本，但是已经能满足我的需求了，我在几个月内都在使用这样的脚本来完成任务。\n直到最近，共用服务器的其他老师反馈说我的任务占用了太多的 CPU 资源，导致他们的实验无法正常进行了，并提醒我要限制 numpy 的线程数。我打开 htop 一看，才发现所有的 CPU 都在满载状态，load average 高达 700~800（服务器有 112 个逻辑 CPU），这时我才意识到问题的严重性。\n紧急 pkill 了所有任务来释放所有资源之后，我按照老师提示的方法设置了 numpy 的线程数，问题才得以解决。\n事后复盘发现，我当时在实验的代码是一段 python 代码，其中的 numpy 模块运行时默认会尝试用所有 CPU 核心进行多线程优化，这是因为 numpy 调用的底层是一些高性能计算库，这些计算库会尽可能利用所有的 CPU. 为了限制这些高性能库榨干服务器的计算资源，需要在调用 numpy 之前先设置环境变量，使这些库认为只有少量的 CPU 可以使用。\nimport os os.environ[\"OMP_NUM_THREADS\"] = \"4\" # OpenMP 线程数 os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\" # OpenBLAS 线程数 os.environ[\"MKL_NUM_THREADS\"] = \"4\" # MKL 线程数 os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\" # NumExpr 线程数 import numpy as np 在设置这些变量后重新运行一段时间后，服务器上出现了其他问题：内存占用过高，可用内存仅剩 10GB/400GB。经过 htop 查看和分析后，导致这些问题的仍然是我的并行任务…\n对于内存的限制还是比较容易的，我在 shell 脚本的最上面加了一行 ulimit -v，限制整个脚本的内存使用量。\n硬盘空间管理 服务器上的硬盘空间是有限的，但是 home 文件夹的膨胀是没有止境的。\n好在实验室有额外加装的硬盘，挂载在 /data 目录下。 最开始，我只是把不太常用的数据集放在了 /data 目录下。但后来随着使用时间的增加，home 文件夹下各类文件也越来越多。按照实验室建议，我开始把一些比较常用，但是占用了较大空间的文件夹都挪到了 /data 目录下，然后用 ln -s 重新软链接回 home 文件夹。\nmv ~/folder /data/my_user_name/folder ln -s /data/my_user_name/folder ~/folder GPU 资源管理 深度学习的任务十分依赖 GPU 加速。服务器上有若干 RTX 4090，但是由于服务器上有其他用户的实验，我们不能随意使用所有的 GPU 资源。\n这一部分实际上分为两个话题，一个是我如何知道自己占用了多少显存，一个是如何合理地分配任务到不同的 GPU 上。\n监控 GPU 资源 查看 GPU 的状态可以使用 nividia 提供的 nvidia-smi 工具，这个工具可以查看 GPU 的使用情况，包括 GPU 的使用率、温度、显存使用情况等等。\n这个工具当然很好用，不过，我需要看到这些显存具体是被哪个用户占用的。更具体地来说，我想要看到我自己占用了多少显存，同时，其他用户中是否有人也正在重度使用 GPU，我是否需要管理自己的任务，降低对服务器的影响。\n因此我在 AI 工具辅助下编写了一个简单的脚本，这个脚本可以查看当前所有用户的显存使用情况，各个 GPU 剩余的显存，以及当前用户的内存使用情况。\n为了方便高亮查看，我把整个脚本的核心代码贴在下面，去掉了 watch -n 1 的前缀。实际使用的脚本中，我使用 watch -n 1 来每秒刷新一次脚本显示，实现实时监控的效果。\n#!/bin/sh nvidia-smi --query-compute-apps=pid,used_memory --format=csv,noheader,nounits | \\ while IFS=',' read -r pid memory; do user=$(ps -o user= -p $pid); echo \"$user,$memory\"; done | awk -F\",\" '\"'\"'{mem[$1]+=$2} END {for (u in mem) print u, mem[u] \" MiB\"}'\"'\"' | \\ awk -v current_user=\"'$(whoami)'\" '\"'\"'{if ($1 == current_user) printf \"%-10s %-10s %-10.2f GB %-10.2f Cards \u003c==\\n\", $1, $2, $2/1024, $2/24576; else printf \"%-10s %-10s %-10.2f GB %-10.2f Cards\\n\", $1, $2, $2/1024, $2/24576}'\"'\"' | sort -k3 -nr | column -t echo \"\" echo \"==============================================\" echo \"Memory usage by me:\" CURRENT_USER=$(whoami) TOTAL_MEMORY=$(ps -u \"$CURRENT_USER\" -o rss= | awk '\"'\"'{sum+=$1} END {print sum}'\"'\"') TOTAL_MEMORY_MB=$((TOTAL_MEMORY / 1024)) TOTAL_MEMORY_GB=$((TOTAL_MEMORY_MB / 1024)) echo \"Total memory usage: $TOTAL_MEMORY_MB MB ($TOTAL_MEMORY_GB GB)\" echo \"\" echo \"==============================================\" echo \"Free memory per GPU:\" nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits | awk '\"'\"'{print $1/1024 \" GB\"}'\"'\"' | column -t 当我运行脚本时，可以看到如下的输出：\nEvery 1.0s: cxhpc: Thu Jan 23 19:22:23 2025 User_A 60806 59.38 GB 2.47 Cards Me 49092 47.94 GB 2.00 Cards \u003c== ============================================== Memory usage by me: Total memory usage: 39969 MB (39 GB) ============================================== Free memory per GPU: 7.61328 GB 21.5918 GB 3.69727 GB 3.69727 GB 9.93164 GB 21.7715 GB 10.1504 GB 2.45312 GB 为了直观显示显存占用的大小，我直接将显存换算为 RTX 4090 显存 24GB 的倍数，即大约占用了多少张显卡。\nGPU 资源分配 使用 pytorch 框架时，可以直接指定使用哪个 GPU，例如：\nimport torch torch.cuda.set_device(1) 有一些场景下，需要保证所有的张量都在同一个 GPU 上，这时可以使用 Tensor.to() 方法，将某个张量转移到指定的 GPU 上。\nimport torch device = torch.device(\"cuda:1\") if torch.cuda.is_available() else \"cpu\" x = torch.randn(5, 3).to(device) 然而，我的实验场景下，最常见的情况是同一个模型要同时在多个数据集上训练。如果在代码中指定某个特定的 GPU，那么无论并行的任务数量多少，所有的任务都会被分配到同一个 GPU 上，大大限制了任务的并行度。\n我为此编写了一个简单的 python 函数，这个函数可以根据当前 GPU 的使用情况，自动选择一个较为空闲的 GPU。\nimport torch import subprocess def get_gpu_memory(): result = subprocess.run( ['nvidia-smi', '--query-gpu=memory.total,memory.used', '--format=csv,nounits,noheader'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True ) if result.returncode != 0: raise RuntimeError(f\"nvidia-smi error: {result.stderr}\") return [tuple(map(int, x.split(', '))) for x in result.stdout.strip().split('\\n')] def get_lowest_memory_gpu(): if not torch.cuda.is_available(): return None gpu_memory = get_gpu_memory() free_memory = [(total - used, i) for i, (total, used) in enumerate(gpu_memory)] _, best_gpu = max(free_memory) if _ \u003c 6000: raise RuntimeError(\"No free GPU available\") print(f'Best GPU: {best_gpu}') return best_gpu opti_device = torch.device(f'cuda:{get_lowest_memory_gpu()}') 这个函数会返回一个较为空闲的 GPU，并直接生成一个名为 opti_device 的 torch.device 对象，可以直接用于 pytorch 的代码中。\n指定 GPU 为 opti_device 后，pytorch 会自动选择一个较为空闲的 GPU 进行计算。\n使用这个 GPU 代码片段，shell 脚本并行任务需要做出一些修改。在提交每个任务需要调用 sleep 命令等待一段时间，使任务有足够的时间把需要的 GPU 显存分配完成。\n#!/bin/bash max_jobs=5 current_jobs=0 for i in {1..10} do if [ $current_jobs -ge $max_jobs ]; then wait -n current_jobs=$((current_jobs-1)) fi nohup python main.py --dataset $i 2\u003e\u00261 \u003e output_$i.log \u0026 current_jobs=$((current_jobs+1)) sleep 30 done 如果不使用 sleep 命令，那么最开始的 max_jobs 个任务会在短时间内同时被提交，这时它们获取的最优 GPU 极有可能是同一个，导致单张卡的显存不足。\n","wordCount":"2717","inLanguage":"en","image":"https://Southern-wood.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-01-23T00:00:00+08:00","dateModified":"2025-01-23T00:00:00+08:00","author":{"@type":"Person","name":"wood"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://Southern-wood.github.io/post/2025/1/how-to-use-resources-on-a-shared-linux-server/"},"publisher":{"@type":"Organization","name":"Southern","logo":{"@type":"ImageObject","url":"https://Southern-wood.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://Southern-wood.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Southern-wood.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://Southern-wood.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://Southern-wood.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://Southern-wood.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://Southern-wood.github.io/post/>Posts</a></div><h1 class="post-title entry-hint-parent">如何在共享的 Linux 服务器上合理使用资源</h1><div class=post-meta><span title='2025-01-23 00:00:00 +0800 CST'>January 23, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;2717 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#ssh-%e8%bf%9e%e6%8e%a5%e5%b7%a5%e5%85%b7 aria-label="SSH 连接工具">SSH 连接工具</a></li><li><a href=#%e5%b9%b6%e8%a1%8c%e5%8c%96%e5%b7%a5%e5%85%b7 aria-label=并行化工具>并行化工具</a></li><li><a href=#cpu-%e8%b5%84%e6%ba%90%e6%8e%a7%e5%88%b6 aria-label="CPU 资源控制">CPU 资源控制</a></li><li><a href=#%e7%a1%ac%e7%9b%98%e7%a9%ba%e9%97%b4%e7%ae%a1%e7%90%86 aria-label=硬盘空间管理>硬盘空间管理</a></li><li><a href=#gpu-%e8%b5%84%e6%ba%90%e7%ae%a1%e7%90%86 aria-label="GPU 资源管理">GPU 资源管理</a><ul><li><a href=#%e7%9b%91%e6%8e%a7-gpu-%e8%b5%84%e6%ba%90 aria-label="监控 GPU 资源">监控 GPU 资源</a></li><li><a href=#gpu-%e8%b5%84%e6%ba%90%e5%88%86%e9%85%8d aria-label="GPU 资源分配">GPU 资源分配</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>我目前在外校的网络安全实验室线上实习，实验室有一台共享的 Linux 服务器，我至今为止的所有工作几乎都是在这台服务器上完成的。</p><p>尽管有一定的 Linux 使用经验，但是我还是在整个实习过程中遇到了比较多的问题。究其原因，使用一台属于自己的 Linux 本地机器，和作为一个普通用户访问共享的 Linux 服务器，这之间还是有较大的区别的。</p><p>这篇文章里，我想分享下我使用服务器中用到的一些工具，遇到的问题以及解决方案。</p><h2 id=ssh-连接工具>SSH 连接工具<a hidden class=anchor aria-hidden=true href=#ssh-连接工具>#</a></h2><p>我找不出任何不推荐 VS Code Remote-SSH 插件的理由。</p><p>只需要简单的配置，你就可以使用本地的 VS Code 终端编辑远程服务器上的文件，同时，所有的插件和配置都能方便地同步到远程服务器上，体验上和本地写代码并没有区别。</p><p>最重要的是，Github Copilot 也能在远程服务器上方便地访问。使用过 AI Copilot 后，我很难回到没有 AI 插件的环境了，由俭入奢易，由奢入俭难啊。</p><h2 id=并行化工具>并行化工具<a hidden class=anchor aria-hidden=true href=#并行化工具>#</a></h2><p>在服务器上，我经常需要同时运行多个任务。特别常见的场景是，同一段代码需要在不同的数据集或者不同的参数设置下进行评估。</p><p>这种情况如果在本地的机器，我可能会用 GNU Parallel；但是服务器上并没有安装这个工具。作为一个替代方案，我常用的方式是手动写一个 shell 脚本来管理任务。</p><p>例如，main.py 这个程序需要在 10 个数据集上运行，我写的 shell 脚本可能会像这样：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>for</span> i in <span class=o>{</span>1..10<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=k>do</span>
</span></span><span class=line><span class=cl>    nohup python main.py --dataset dataset_<span class=nv>$i</span> 2&gt;<span class=p>&amp;</span><span class=m>1</span> &gt; output_<span class=nv>$i</span>.log <span class=p>&amp;</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span></code></pre></div><p>这里的 nohup 是用来创建后台进程，如果不使用 nohup 直接运行 python main.py，在 SSH 连接中断后程序会停止运行；& 是用来将任务放到后台运行，和当前的终端分离。</p><p>当然，这是只是最粗糙的并行脚本，它的问题有很多，最容易想到的有两点：</p><ul><li>一些任务可能会占用太多的 CPU/GPU 资源，导致服务器上的其他任务无法正常运行。</li><li>所有任务的输出都被 nohup 默认重定向到 nohup.out 文件，这样会导致输出混乱，不方便查看。</li></ul><p>所以，我实际上会在脚本里手动控制并行任务的数量，并将输出重定向到不同的文件中。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=nv>max_jobs</span><span class=o>=</span><span class=m>5</span>
</span></span><span class=line><span class=cl><span class=nv>current_jobs</span><span class=o>=</span><span class=m>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> i in <span class=o>{</span>1..10<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=k>do</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=o>[</span> <span class=nv>$current_jobs</span> -ge <span class=nv>$max_jobs</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=cl>        <span class=nb>wait</span> -n
</span></span><span class=line><span class=cl>        <span class=nv>current_jobs</span><span class=o>=</span><span class=k>$((</span>current_jobs-1<span class=k>))</span>
</span></span><span class=line><span class=cl>    <span class=k>fi</span>
</span></span><span class=line><span class=cl>    nohup python main.py --dataset <span class=nv>$i</span> 2&gt;<span class=p>&amp;</span><span class=m>1</span> &gt; output_<span class=nv>$i</span>.log <span class=p>&amp;</span>
</span></span><span class=line><span class=cl>    <span class=nv>current_jobs</span><span class=o>=</span><span class=k>$((</span>current_jobs+1<span class=k>))</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span></code></pre></div><h2 id=cpu-资源控制>CPU 资源控制<a hidden class=anchor aria-hidden=true href=#cpu-资源控制>#</a></h2><p>虽然上面展示的仍然是一个比较粗糙和简单的脚本，但是已经能满足我的需求了，我在几个月内都在使用这样的脚本来完成任务。</p><p>直到最近，共用服务器的其他老师反馈说我的任务占用了太多的 CPU 资源，导致他们的实验无法正常进行了，并提醒我要限制 numpy 的线程数。我打开 htop 一看，才发现所有的 CPU 都在满载状态，load average 高达 700~800（服务器有 112 个逻辑 CPU），这时我才意识到问题的严重性。</p><p>紧急 pkill 了所有任务来释放所有资源之后，我按照老师提示的方法设置了 numpy 的线程数，问题才得以解决。</p><p>事后复盘发现，我当时在实验的代码是一段 python 代码，其中的 numpy 模块运行时默认会尝试用所有 CPU 核心进行多线程优化，这是因为 numpy 调用的底层是一些高性能计算库，这些计算库会尽可能利用所有的 CPU. 为了限制这些高性能库榨干服务器的计算资源，需要在调用 numpy 之前先设置环境变量，使这些库认为只有少量的 CPU 可以使用。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;OMP_NUM_THREADS&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;4&#34;</span>  <span class=c1># OpenMP 线程数</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;OPENBLAS_NUM_THREADS&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;4&#34;</span>  <span class=c1># OpenBLAS 线程数</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;MKL_NUM_THREADS&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;4&#34;</span>  <span class=c1># MKL 线程数</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;NUMEXPR_NUM_THREADS&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;4&#34;</span>  <span class=c1># NumExpr 线程数</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span></code></pre></div><p>在设置这些变量后重新运行一段时间后，服务器上出现了其他问题：内存占用过高，可用内存仅剩 10GB/400GB。经过 htop 查看和分析后，导致这些问题的仍然是我的并行任务&mldr;</p><p>对于内存的限制还是比较容易的，我在 shell 脚本的最上面加了一行 <code>ulimit -v</code>，限制整个脚本的内存使用量。</p><h2 id=硬盘空间管理>硬盘空间管理<a hidden class=anchor aria-hidden=true href=#硬盘空间管理>#</a></h2><p>服务器上的硬盘空间是有限的，但是 home 文件夹的膨胀是没有止境的。</p><p>好在实验室有额外加装的硬盘，挂载在 <code>/data</code> 目录下。
最开始，我只是把不太常用的数据集放在了 <code>/data</code> 目录下。但后来随着使用时间的增加，home 文件夹下各类文件也越来越多。按照实验室建议，我开始把一些比较常用，但是占用了较大空间的文件夹都挪到了 <code>/data</code> 目录下，然后用 <code>ln -s</code> 重新软链接回 home 文件夹。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>mv ~/folder /data/my_user_name/folder
</span></span><span class=line><span class=cl>ln -s /data/my_user_name/folder ~/folder
</span></span></code></pre></div><h2 id=gpu-资源管理>GPU 资源管理<a hidden class=anchor aria-hidden=true href=#gpu-资源管理>#</a></h2><p>深度学习的任务十分依赖 GPU 加速。服务器上有若干 RTX 4090，但是由于服务器上有其他用户的实验，我们不能随意使用所有的 GPU 资源。</p><p>这一部分实际上分为两个话题，一个是我如何知道自己占用了多少显存，一个是如何合理地分配任务到不同的 GPU 上。</p><h3 id=监控-gpu-资源>监控 GPU 资源<a hidden class=anchor aria-hidden=true href=#监控-gpu-资源>#</a></h3><p>查看 GPU 的状态可以使用 nividia 提供的 nvidia-smi 工具，这个工具可以查看 GPU 的使用情况，包括 GPU 的使用率、温度、显存使用情况等等。</p><p>这个工具当然很好用，不过，我需要看到这些显存具体是被哪个用户占用的。更具体地来说，我想要看到我自己占用了多少显存，同时，其他用户中是否有人也正在重度使用 GPU，我是否需要管理自己的任务，降低对服务器的影响。</p><p>因此我在 AI 工具辅助下编写了一个简单的脚本，这个脚本可以查看当前所有用户的显存使用情况，各个 GPU 剩余的显存，以及当前用户的内存使用情况。</p><p>为了方便高亮查看，我把整个脚本的核心代码贴在下面，去掉了 watch -n 1 的前缀。实际使用的脚本中，我使用 watch -n 1 来每秒刷新一次脚本显示，实现实时监控的效果。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=cp>#!/bin/sh
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl>nvidia-smi --query-compute-apps<span class=o>=</span>pid,used_memory --format<span class=o>=</span>csv,noheader,nounits <span class=p>|</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=k>while</span> <span class=nv>IFS</span><span class=o>=</span><span class=s1>&#39;,&#39;</span> <span class=nb>read</span> -r pid memory<span class=p>;</span> <span class=k>do</span> 
</span></span><span class=line><span class=cl>  <span class=nv>user</span><span class=o>=</span><span class=k>$(</span>ps -o <span class=nv>user</span><span class=o>=</span> -p <span class=nv>$pid</span><span class=k>)</span><span class=p>;</span> 
</span></span><span class=line><span class=cl>  <span class=nb>echo</span> <span class=s2>&#34;</span><span class=nv>$user</span><span class=s2>,</span><span class=nv>$memory</span><span class=s2>&#34;</span><span class=p>;</span> 
</span></span><span class=line><span class=cl><span class=k>done</span> <span class=p>|</span> awk -F<span class=s2>&#34;,&#34;</span> <span class=s1>&#39;&#34;&#39;</span><span class=s2>&#34;&#39;{mem[</span><span class=nv>$1</span><span class=s2>]+=</span><span class=nv>$2</span><span class=s2>} END {for (u in mem) print u, mem[u] &#34;</span> MiB<span class=s2>&#34;}&#39;&#34;</span><span class=s1>&#39;&#34;&#39;</span> <span class=p>|</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>        awk -v <span class=nv>current_user</span><span class=o>=</span><span class=s2>&#34;&#39;</span><span class=k>$(</span>whoami<span class=k>)</span><span class=s2>&#39;&#34;</span> <span class=s1>&#39;&#34;&#39;</span><span class=s2>&#34;&#39;{if (</span><span class=nv>$1</span><span class=s2> == current_user) printf &#34;</span>%-10s %-10s %-10.2f GB %-10.2f Cards &lt;<span class=o>==</span><span class=se>\n</span><span class=s2>&#34;, </span><span class=nv>$1</span><span class=s2>, </span><span class=nv>$2</span><span class=s2>, </span><span class=nv>$2</span><span class=s2>/1024, </span><span class=nv>$2</span><span class=s2>/24576; else printf &#34;</span>%-10s %-10s %-10.2f GB %-10.2f Cards<span class=se>\n</span><span class=s2>&#34;, </span><span class=nv>$1</span><span class=s2>, </span><span class=nv>$2</span><span class=s2>, </span><span class=nv>$2</span><span class=s2>/1024, </span><span class=nv>$2</span><span class=s2>/24576}&#39;&#34;</span><span class=s1>&#39;&#34;&#39;</span> <span class=p>|</span> sort -k3 -nr <span class=p>|</span> column -t
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;==============================================&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;Memory usage by me:&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>CURRENT_USER</span><span class=o>=</span><span class=k>$(</span>whoami<span class=k>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>TOTAL_MEMORY</span><span class=o>=</span><span class=k>$(</span>ps -u <span class=s2>&#34;</span><span class=nv>$CURRENT_USER</span><span class=s2>&#34;</span> -o <span class=nv>rss</span><span class=o>=</span> <span class=p>|</span> awk <span class=s1>&#39;&#34;&#39;</span><span class=s2>&#34;&#39;{sum+=</span><span class=nv>$1</span><span class=s2>} END {print sum}&#39;&#34;</span><span class=s1>&#39;&#34;&#39;</span><span class=k>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>TOTAL_MEMORY_MB</span><span class=o>=</span><span class=k>$((</span>TOTAL_MEMORY <span class=o>/</span> <span class=m>1024</span><span class=k>))</span>
</span></span><span class=line><span class=cl><span class=nv>TOTAL_MEMORY_GB</span><span class=o>=</span><span class=k>$((</span>TOTAL_MEMORY_MB <span class=o>/</span> <span class=m>1024</span><span class=k>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;Total memory usage: </span><span class=nv>$TOTAL_MEMORY_MB</span><span class=s2> MB (</span><span class=nv>$TOTAL_MEMORY_GB</span><span class=s2> GB)&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;==============================================&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;Free memory per GPU:&#34;</span>
</span></span><span class=line><span class=cl>nvidia-smi --query-gpu<span class=o>=</span>memory.free --format<span class=o>=</span>csv,noheader,nounits <span class=p>|</span> awk <span class=s1>&#39;&#34;&#39;</span><span class=s2>&#34;&#39;{print </span><span class=nv>$1</span><span class=s2>/1024 &#34;</span> GB<span class=s2>&#34;}&#39;&#34;</span><span class=s1>&#39;&#34;&#39;</span> <span class=p>|</span> column -t
</span></span></code></pre></div><p>当我运行脚本时，可以看到如下的输出：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>Every 1.0s:                                 cxhpc: Thu Jan <span class=m>23</span> 19:22:23 <span class=m>2025</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>User_A      <span class=m>60806</span>  59.38  GB  2.47  Cards
</span></span><span class=line><span class=cl>Me          <span class=m>49092</span>  47.94  GB  2.00  Cards  &lt;<span class=o>==</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>==============================================</span>
</span></span><span class=line><span class=cl>Memory usage by me:
</span></span><span class=line><span class=cl>Total memory usage: <span class=m>39969</span> MB <span class=o>(</span><span class=m>39</span> GB<span class=o>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>==============================================</span>
</span></span><span class=line><span class=cl>Free memory per GPU:
</span></span><span class=line><span class=cl>7.61328  GB
</span></span><span class=line><span class=cl>21.5918  GB
</span></span><span class=line><span class=cl>3.69727  GB
</span></span><span class=line><span class=cl>3.69727  GB
</span></span><span class=line><span class=cl>9.93164  GB
</span></span><span class=line><span class=cl>21.7715  GB
</span></span><span class=line><span class=cl>10.1504  GB
</span></span><span class=line><span class=cl>2.45312  GB
</span></span></code></pre></div><p>为了直观显示显存占用的大小，我直接将显存换算为 RTX 4090 显存 24GB 的倍数，即大约占用了多少张显卡。</p><h3 id=gpu-资源分配>GPU 资源分配<a hidden class=anchor aria-hidden=true href=#gpu-资源分配>#</a></h3><p>使用 pytorch 框架时，可以直接指定使用哪个 GPU，例如：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>set_device</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><p>有一些场景下，需要保证所有的张量都在同一个 GPU 上，这时可以使用 Tensor.to() 方法，将某个张量转移到指定的 GPU 上。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda:1&#34;</span><span class=p>)</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span></code></pre></div><p>然而，我的实验场景下，最常见的情况是同一个模型要同时在多个数据集上训练。如果在代码中指定某个特定的 GPU，那么无论并行的任务数量多少，所有的任务都会被分配到同一个 GPU 上，大大限制了任务的并行度。</p><p>我为此编写了一个简单的 python 函数，这个函数可以根据当前 GPU 的使用情况，自动选择一个较为空闲的 GPU。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>subprocess</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_gpu_memory</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=s1>&#39;nvidia-smi&#39;</span><span class=p>,</span> <span class=s1>&#39;--query-gpu=memory.total,memory.used&#39;</span><span class=p>,</span> <span class=s1>&#39;--format=csv,nounits,noheader&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>stdout</span><span class=o>=</span><span class=n>subprocess</span><span class=o>.</span><span class=n>PIPE</span><span class=p>,</span> <span class=n>stderr</span><span class=o>=</span><span class=n>subprocess</span><span class=o>.</span><span class=n>PIPE</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;nvidia-smi error: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=nb>tuple</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;, &#39;</span><span class=p>)))</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>result</span><span class=o>.</span><span class=n>stdout</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_lowest_memory_gpu</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>gpu_memory</span> <span class=o>=</span> <span class=n>get_gpu_memory</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>free_memory</span> <span class=o>=</span> <span class=p>[(</span><span class=n>total</span> <span class=o>-</span> <span class=n>used</span><span class=p>,</span> <span class=n>i</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>total</span><span class=p>,</span> <span class=n>used</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>gpu_memory</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>_</span><span class=p>,</span> <span class=n>best_gpu</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>free_memory</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>_</span> <span class=o>&lt;</span> <span class=mi>6000</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;No free GPU available&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Best GPU: </span><span class=si>{</span><span class=n>best_gpu</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>best_gpu</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>opti_device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;cuda:</span><span class=si>{</span><span class=n>get_lowest_memory_gpu</span><span class=p>()</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>这个函数会返回一个较为空闲的 GPU，并直接生成一个名为 opti_device 的 torch.device 对象，可以直接用于 pytorch 的代码中。</p><p>指定 GPU 为 opti_device 后，pytorch 会自动选择一个较为空闲的 GPU 进行计算。</p><p>使用这个 GPU 代码片段，shell 脚本并行任务需要做出一些修改。在提交每个任务需要调用 <code>sleep</code> 命令等待一段时间，使任务有足够的时间把需要的 GPU 显存分配完成。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=nv>max_jobs</span><span class=o>=</span><span class=m>5</span>
</span></span><span class=line><span class=cl><span class=nv>current_jobs</span><span class=o>=</span><span class=m>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> i in <span class=o>{</span>1..10<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=k>do</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=o>[</span> <span class=nv>$current_jobs</span> -ge <span class=nv>$max_jobs</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=cl>        <span class=nb>wait</span> -n
</span></span><span class=line><span class=cl>        <span class=nv>current_jobs</span><span class=o>=</span><span class=k>$((</span>current_jobs-1<span class=k>))</span>
</span></span><span class=line><span class=cl>    <span class=k>fi</span>
</span></span><span class=line><span class=cl>    nohup python main.py --dataset <span class=nv>$i</span> 2&gt;<span class=p>&amp;</span><span class=m>1</span> &gt; output_<span class=nv>$i</span>.log <span class=p>&amp;</span>
</span></span><span class=line><span class=cl>    <span class=nv>current_jobs</span><span class=o>=</span><span class=k>$((</span>current_jobs+1<span class=k>))</span>
</span></span><span class=line><span class=cl>    sleep <span class=m>30</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span></code></pre></div><p>如果不使用 sleep 命令，那么最开始的 max_jobs 个任务会在短时间内同时被提交，这时它们获取的最优 GPU 极有可能是同一个，导致单张卡的显存不足。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://Southern-wood.github.io/tags/linux/>Linux</a></li></ul><nav class=paginav><a class=next href=https://Southern-wood.github.io/post/2024/12/run-ubuntu-on-mac-with-docker/pic/><span class=title>Next »</span><br><span>如何使用 docker 在 Mac 上运行并配置 Ubuntu</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://Southern-wood.github.io/>Southern</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>